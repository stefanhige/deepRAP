{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepRAP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import nibabel as nib\n",
    "import gdown\n",
    "import warnings\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "import scipy.ndimage\n",
    "import skimage.exposure\n",
    "import skimage.morphology\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional\n",
    "import time\n",
    "import networkx as nx\n",
    "import json\n",
    "from matplotlib.cm import ScalarMappable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PREFIX = \".\"\n",
    "\n",
    "input_file = os.path.join(FILE_PREFIX, \"R_20190430164629_Stefan_LF.npy.npz\")\n",
    "model_file_layerseg = os.path.join(FILE_PREFIX, \"mod210616-00_last_.pt\")\n",
    "model_file_vesselseg = os.path.join(FILE_PREFIX, \"mod210702-01.pt\")\n",
    "\n",
    "# only works with this specific version of gdown\n",
    "# !pip install gdown==4.6.0\n",
    "assert gdown.__version__ == \"4.6.0\"\n",
    "\n",
    "if not os.path.exists(input_file):\n",
    "    gdown.download(id=\"1oV3cr4YJlGsfhxkOwW4PEcMi6DOLNEXC\", output=input_file, quiet=False)\n",
    "if not os.path.exists(model_file_layerseg):\n",
    "    gdown.download(id=\"1lLEhdOQXMWMH_dxRd9_VNcFNO_8tisMd\", output=model_file_layerseg, quiet=False)\n",
    "if not os.path.exists(model_file_vesselseg):\n",
    "    gdown.download(id=\"1SDhvfDOCJ30_7RpDg7JV_GfI5akdoss6\", output=model_file_vesselseg, quiet=False)\n",
    "\n",
    "data = np.load(input_file)\n",
    "raw_rsom_lf = data[\"lf\"]\n",
    "raw_rsom_hf = data[\"hf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Segmentation\n",
    "### Preprocessing\n",
    "\n",
    "Calculate the maximum intensity projection for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mip(vol_lf: ndarray, vol_hf: ndarray, axis: int = 1) -> ndarray:\n",
    "    # maximum intensity projection\n",
    "    mip_lf = np.amax(vol_lf, axis=axis)\n",
    "    mip_hf = np.amax(vol_hf, axis=axis)\n",
    "\n",
    "    # calculate scaling factor alpha in between lf and hf channel\n",
    "    # to maximize contrast\n",
    "    alpha = scipy.optimize.minimize_scalar(\n",
    "        lambda x: np.sum(np.square(mip_lf - x * mip_hf)),\n",
    "        bounds=(0, 100),\n",
    "        method=\"bounded\",\n",
    "    ).x\n",
    "\n",
    "    mip_rgb = np.dstack([mip_lf, alpha * mip_hf, np.zeros_like(mip_lf)])\n",
    "    mip_rgb = mip_rgb.clip(0, np.inf)\n",
    "    mip_rgb = skimage.exposure.rescale_intensity(mip_rgb, out_range=np.uint8).astype(\n",
    "        np.uint8\n",
    "    )\n",
    "    quantiles = np.quantile(mip_rgb, (0.8, 0.9925))\n",
    "    mip_rgb = skimage.exposure.rescale_intensity(\n",
    "        mip_rgb, in_range=(quantiles[0], quantiles[1]), out_range=np.uint8\n",
    "    )\n",
    "    return mip_rgb\n",
    "\n",
    "\n",
    "mip_rgb = calculate_mip(raw_rsom_lf, raw_rsom_hf)\n",
    "plt.figure()\n",
    "plt.imshow(mip_rgb)\n",
    "plt.title(\"MIP\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the volume by applying the intensity transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_rgb_volume(\n",
    "    vol_lf: ndarray, vol_hf: ndarray, upper_bound: dict, lower_bound: dict\n",
    ") -> ndarray:\n",
    "    vol_lf_norm = vol_lf / np.amax(vol_lf)\n",
    "    vol_hf_norm = vol_hf / np.amax(vol_hf)\n",
    "\n",
    "    vol_lf_norm = np.clip(vol_lf_norm, 0, 1)\n",
    "    vol_hf_norm = np.clip(vol_hf_norm, 0, 1)\n",
    "\n",
    "    vol_lf_norm = skimage.exposure.rescale_intensity(\n",
    "        vol_lf_norm, in_range=(0, upper_bound[\"lf\"])\n",
    "    )\n",
    "    vol_hf_norm = skimage.exposure.rescale_intensity(\n",
    "        vol_hf_norm, in_range=(0, upper_bound[\"hf\"])\n",
    "    )\n",
    "\n",
    "    # square\n",
    "    vol_lf_norm = vol_lf_norm**2\n",
    "    vol_hf_norm = vol_hf_norm**2\n",
    "\n",
    "    vol_lf_norm = skimage.exposure.rescale_intensity(\n",
    "        vol_lf_norm, in_range=(lower_bound[\"lf\"], 1)\n",
    "    )\n",
    "    vol_hf_norm = skimage.exposure.rescale_intensity(\n",
    "        vol_hf_norm, in_range=(lower_bound[\"hf\"], 1)\n",
    "    )\n",
    "\n",
    "    vol_rgb = 255 * np.stack(\n",
    "        [vol_lf_norm, vol_hf_norm, np.zeros_like(vol_lf_norm)], axis=-1\n",
    "    )\n",
    "    return vol_rgb.astype(np.uint8)\n",
    "\n",
    "\n",
    "vol_rgb = prepare_rgb_volume(\n",
    "    raw_rsom_lf,\n",
    "    raw_rsom_hf,\n",
    "    upper_bound={\"lf\": 0.2, \"hf\": 0.1},\n",
    "    lower_bound={\"lf\": 0.05, \"hf\": 0.02},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the tensor by applying the sliding window maximum intensity projection and converting to the correct type and shape.\n",
    "\n",
    "Additionally, define the inverse function to transform the tensor back into a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tensor(data, sliding_window_size):\n",
    "    def sliding_window_mip(data, sliding_window_size):\n",
    "        data_mip_x = scipy.ndimage.maximum_filter1d(\n",
    "            data, size=sliding_window_size, axis=1\n",
    "        )\n",
    "        data_mip_y = scipy.ndimage.maximum_filter1d(\n",
    "            data, size=sliding_window_size, axis=2\n",
    "        )\n",
    "\n",
    "        return data_mip_x, data_mip_y\n",
    "\n",
    "    data_sliding_mip_x, data_sliding_mip_y = sliding_window_mip(\n",
    "        data, sliding_window_size\n",
    "    )\n",
    "\n",
    "    # 500 to axis 1\n",
    "    data_sliding_mip_x = np.swapaxes(data_sliding_mip_x, 0, 1)\n",
    "    # 500 to axis 1\n",
    "    data_sliding_mip_y = np.swapaxes(data_sliding_mip_y, 0, 1)\n",
    "    # swap\n",
    "    data_sliding_mip_y = np.swapaxes(data_sliding_mip_y, 0, 2)\n",
    "\n",
    "    class Crop:\n",
    "        def __init__(self, unet_depth):\n",
    "            self.maxdiv = 2 ** (unet_depth - 1)\n",
    "\n",
    "        def __call__(self, data, meta):\n",
    "            # easy version: first crop to even, crop rest afterwards, if necessary\n",
    "            initial_dshape = data.shape\n",
    "\n",
    "            is_odd = np.mod(data.shape[:-1], 2)\n",
    "\n",
    "            # batch dimension is first dimension\n",
    "            data = data[:, is_odd[1] :, is_odd[2] :, :]\n",
    "\n",
    "            # save, how much data was cropped\n",
    "            meta[\"crop\"] = {}\n",
    "            meta[\"crop\"][\"begin\"] = np.array([0, is_odd[1], is_odd[2], 0], dtype=int)\n",
    "            meta[\"crop\"][\"end\"] = np.array([0, 0, 0, 0], dtype=int)\n",
    "\n",
    "            # check if Z and Y are divisible through self.maxdiv\n",
    "            rem1 = np.mod(data.shape[1], self.maxdiv)\n",
    "            rem2 = np.mod(data.shape[2], self.maxdiv)\n",
    "\n",
    "            if rem1 or rem2:\n",
    "                if rem1:\n",
    "                    # crop Z\n",
    "                    data = data[\n",
    "                        :, int(np.floor(rem1 / 2)) : -int(np.ceil(rem1 / 2)), :, :\n",
    "                    ]\n",
    "\n",
    "                if rem2:\n",
    "                    # crop Y\n",
    "                    data = data[\n",
    "                        :, :, int(np.floor(rem2 / 2)) : -int(np.ceil(rem2 / 2)), :\n",
    "                    ]\n",
    "\n",
    "                # add to meta information, how much has been cropped\n",
    "                meta[\"crop\"][\"begin\"] += np.array(\n",
    "                    [0, np.floor(rem1 / 2), np.floor(rem2 / 2), 0], dtype=int\n",
    "                )\n",
    "                meta[\"crop\"][\"end\"] += np.array(\n",
    "                    [0, np.ceil(rem1 / 2), np.ceil(rem2 / 2), 0], dtype=int\n",
    "                )\n",
    "\n",
    "            assert np.all(\n",
    "                np.array(initial_dshape)\n",
    "                == meta[\"crop\"][\"begin\"] + meta[\"crop\"][\"end\"] + np.array(data.shape)\n",
    "            ), \"Shapes and Crop do not match\"\n",
    "            return data, meta\n",
    "\n",
    "    class ToTensor:\n",
    "        \"\"\"\n",
    "        Convert np.ndarray to Tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        def __call__(self, data, meta):\n",
    "            # drop blue channel, it is empty\n",
    "            if data.shape[-1] == 3:\n",
    "                data = data[..., :2]\n",
    "\n",
    "            # move channel axis\n",
    "            data = np.moveaxis(data, -1, 1)\n",
    "\n",
    "            data = torch.from_numpy(data)\n",
    "\n",
    "            return data.contiguous(), meta\n",
    "\n",
    "    meta_x = {\"batch_axis\": \"x\"}\n",
    "    meta_y = {\"batch_axis\": \"y\"}\n",
    "    for transform in [Crop(unet_depth=5), ToTensor()]:\n",
    "        data_sliding_mip_x, meta_x = transform(data_sliding_mip_x, meta_x)\n",
    "        data_sliding_mip_y, meta_y = transform(data_sliding_mip_y, meta_y)\n",
    "\n",
    "    return data_sliding_mip_x, meta_x, data_sliding_mip_y, meta_y\n",
    "\n",
    "\n",
    "def to_numpy(volume, meta):\n",
    "    if not isinstance(volume, np.ndarray):\n",
    "        assert isinstance(volume, torch.Tensor)\n",
    "        volume = volume.numpy()\n",
    "\n",
    "    volume = np.squeeze(volume, axis=1)\n",
    "\n",
    "    # add padding from meta['crop']\n",
    "    # structure for np.pad\n",
    "    # (before0, after0), (before1, after1), ..)\n",
    "\n",
    "    b = (meta[\"crop\"][\"begin\"]).squeeze()[:-1]\n",
    "    e = (meta[\"crop\"][\"end\"]).squeeze()[:-1]\n",
    "\n",
    "    pad_width = list(zip(b, e))\n",
    "\n",
    "    volume = np.pad(volume, pad_width, \"edge\")\n",
    "\n",
    "    batch_axis = meta[\"batch_axis\"]\n",
    "    if isinstance(batch_axis, list):\n",
    "        batch_axis = batch_axis[0]\n",
    "\n",
    "    if batch_axis == \"x\":\n",
    "        volume = volume.transpose((1, 0, 2))\n",
    "    elif batch_axis == \"y\":\n",
    "        volume = volume.transpose((1, 2, 0))\n",
    "    else:\n",
    "        raise AttributeError\n",
    "\n",
    "    return np.ascontiguousarray(volume)\n",
    "\n",
    "\n",
    "data_x, meta_x, data_y, meta_y = prepare_tensor(vol_rgb, sliding_window_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check the shapes of our input data for the layer segmentation. We have two inputs, one for each direction of the skin plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_x.shape)\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Segmentation Model\n",
    "\n",
    "Define the layer segmentation model (UNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/jvanvugt/pytorch-unet\n",
    "# Adapted from https://discuss.pytorch.org/t/unet-implementation/426\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=1,\n",
    "        n_classes=2,\n",
    "        depth=5,\n",
    "        wf=6,\n",
    "        padding=False,\n",
    "        batch_norm=False,\n",
    "        up_mode=\"upconv\",\n",
    "        dropout=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Implementation of\n",
    "        U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    "        (Ronneberger et al., 2015)\n",
    "        https://arxiv.org/abs/1505.04597\n",
    "\n",
    "        Using the default arguments will yield the exact version used\n",
    "        in the original paper\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): number of input channels\n",
    "            n_classes (int): number of output channels\n",
    "            depth (int): depth of the network\n",
    "            wf (int): number of filters in the first layer is 2**wf\n",
    "            padding (bool): if True, apply padding such that the input shape\n",
    "                            is the same as the output.\n",
    "                            This may introduce artifacts\n",
    "            batch_norm (bool): Use BatchNorm after layers with an\n",
    "                                activation function\n",
    "            up_mode (str): one of 'upconv' or 'upsample'.\n",
    "                            'upconv' will use transposed convolutions for\n",
    "                            learned upsampling.\n",
    "                            'upsample' will use bilinear upsampling.\n",
    "            dropout (bool) if True, add dropout layer in up block\n",
    "        \"\"\"\n",
    "        super(UNet, self).__init__()\n",
    "        assert up_mode in (\"upconv\", \"upsample\")\n",
    "        self.padding = padding\n",
    "        self.depth = depth\n",
    "        self.dropout = dropout\n",
    "        prev_channels = in_channels\n",
    "        self.down_path = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.down_path.append(\n",
    "                UNetConvBlock(prev_channels, 2 ** (wf + i), padding, batch_norm)\n",
    "            )\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        self.up_path = nn.ModuleList()\n",
    "        for i in reversed(range(depth - 1)):\n",
    "            if self.dropout and i < depth - 2:\n",
    "                self.up_path.append(\n",
    "                    UNetUpBlock(\n",
    "                        prev_channels, 2 ** (wf + i), up_mode, padding, batch_norm, True\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                self.up_path.append(\n",
    "                    UNetUpBlock(\n",
    "                        prev_channels,\n",
    "                        2 ** (wf + i),\n",
    "                        up_mode,\n",
    "                        padding,\n",
    "                        batch_norm,\n",
    "                        False,\n",
    "                    )\n",
    "                )\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        self.last = nn.Conv2d(prev_channels, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        blocks = []\n",
    "        for i, down in enumerate(self.down_path):\n",
    "            x = down(x)\n",
    "            if i != len(self.down_path) - 1:\n",
    "                blocks.append(x)\n",
    "                x = torch.nn.functional.max_pool2d(x, 2)\n",
    "\n",
    "        for i, up in enumerate(self.up_path):\n",
    "            x = up(x, blocks[-i - 1])\n",
    "\n",
    "        return self.last(x)\n",
    "\n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "class UNetConvBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, padding, batch_norm):\n",
    "        super(UNetConvBlock, self).__init__()\n",
    "        block = []\n",
    "\n",
    "        block.append(nn.Conv2d(in_size, out_size, kernel_size=3, padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        block.append(nn.Conv2d(out_size, out_size, kernel_size=3, padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class UNetUpBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, up_mode, padding, batch_norm, dropout):\n",
    "        super(UNetUpBlock, self).__init__()\n",
    "        if up_mode == \"upconv\":\n",
    "            self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2, stride=2)\n",
    "        elif up_mode == \"upsample\":\n",
    "            self.up = nn.Sequential(\n",
    "                nn.Upsample(mode=\"bilinear\", scale_factor=2, align_corners=True),\n",
    "                nn.Conv2d(in_size, out_size, kernel_size=1),\n",
    "            )\n",
    "\n",
    "        self.is_dropout = dropout\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.conv_block = UNetConvBlock(in_size, out_size, padding, batch_norm)\n",
    "\n",
    "    def center_crop(self, layer, target_size):\n",
    "        _, _, layer_height, layer_width = layer.size()\n",
    "        diff_y = (layer_height - target_size[0]) // 2\n",
    "        diff_x = (layer_width - target_size[1]) // 2\n",
    "        return layer[\n",
    "            :, :, diff_y : (diff_y + target_size[0]), diff_x : (diff_x + target_size[1])\n",
    "        ]\n",
    "\n",
    "    def forward(self, x, bridge):\n",
    "        up = self.up(x)\n",
    "        crop1 = self.center_crop(bridge, up.shape[2:])\n",
    "        out = torch.cat([up, crop1], 1)\n",
    "        if self.is_dropout:\n",
    "            out = self.dropout(out)\n",
    "        else:\n",
    "            pass\n",
    "        out = self.conv_block(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = UNet(\n",
    "    in_channels=2,\n",
    "    n_classes=1,\n",
    "    depth=5,\n",
    "    wf=6,\n",
    "    padding=True,\n",
    "    batch_norm=True,\n",
    "    up_mode=\"upconv\",\n",
    "    dropout=True,  # not relevant for predict\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.load_state_dict(torch.load(model_file_layerseg))\n",
    "else:\n",
    "    model.load_state_dict(torch.load(model_file_layerseg, map_location=torch.device('cpu')))\n",
    "\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# cuda_dtype = torch.bfloat16\n",
    "cuda_dtype = torch.float32\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "model.to(device, cuda_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the inference function and run layer segmentation prediction on the example dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(*, data_x, meta_x, data_y, meta_y, model):\n",
    "    def _predict_one(batch, model):\n",
    "        batch = batch.to(device, cuda_dtype)\n",
    "\n",
    "        # divide into minibatches\n",
    "        minibatches = np.arange(batch.shape[0], step=batch_size)\n",
    "\n",
    "        # init empty prediction stack\n",
    "        shp = batch.shape\n",
    "        # [0 x 2 x 500 x 332]\n",
    "        prediction_stack = torch.zeros(\n",
    "            (0, 1, shp[2], shp[3]), dtype=cuda_dtype, requires_grad=False\n",
    "        )\n",
    "\n",
    "        for _, idx in enumerate(minibatches):\n",
    "            data = batch[idx : idx + batch_size, ...]\n",
    "            prediction = model(data)\n",
    "\n",
    "            prediction = prediction.detach()\n",
    "            prediction = prediction.to(\"cpu\")\n",
    "            prediction_stack = torch.cat((prediction_stack, prediction), dim=0)\n",
    "\n",
    "        # transform -> labels\n",
    "        prediction_stack = torch.sigmoid(prediction_stack.float())\n",
    "\n",
    "        return prediction_stack\n",
    "\n",
    "    pred_tensor_x = _predict_one(batch=data_x, model=model)\n",
    "    prob_x = to_numpy(pred_tensor_x, meta_x)\n",
    "    pred_tensor_y = _predict_one(batch=data_y, model=model)\n",
    "    prob_y = to_numpy(pred_tensor_y, meta_y)\n",
    "    combined = (prob_x + prob_y) / 2\n",
    "\n",
    "    return combined\n",
    "\n",
    "\n",
    "epidermis_prob = predict(\n",
    "    data_x=data_x, meta_x=meta_x, data_y=data_y, meta_y=meta_y, model=model\n",
    ")\n",
    "\n",
    "# set decision boundary to 0.5\n",
    "is_epidermis = epidermis_prob >= 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Segmentation Results\n",
    "\n",
    "Visualize the segmentation result with a semitransparent overlay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_segmentation_overlay(mip, segmentation, axis):\n",
    "    def _overlay(data, seg, alpha, colour=(255, 255, 255)):\n",
    "        seg_mask = seg.copy()\n",
    "        seg_mask = np.dstack((seg_mask, seg_mask, seg_mask)).astype(bool)\n",
    "        seg_rgb = np.dstack((colour[0] * seg, colour[1] * seg, colour[2] * seg))\n",
    "\n",
    "        ol = (\n",
    "            (alpha * seg_mask.astype(np.uint8) * data)\n",
    "            + (np.logical_not(seg_mask).astype(np.uint8) * data)\n",
    "            + (1 - alpha) * seg_rgb\n",
    "        )\n",
    "\n",
    "        return ol.clip(0, 255).astype(np.uint8)\n",
    "\n",
    "    segmentation = np.amax(segmentation, axis=axis)\n",
    "\n",
    "    return _overlay(mip, segmentation.astype(np.float32), alpha=0.4)\n",
    "\n",
    "\n",
    "mip_epidermis_overlay = calculate_segmentation_overlay(mip_rgb, is_epidermis, 1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(mip_rgb)\n",
    "ax[1].imshow(mip_epidermis_overlay)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vessel Segmentation\n",
    "### Preprocessing\n",
    "\n",
    "Post-process the epidermis segmentation mask by smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_epidermis_seg(vol_):\n",
    "    vol = copy.deepcopy(vol_)\n",
    "    vol_shape = vol.shape\n",
    "    structure = scipy.ndimage.generate_binary_structure(3, 2)\n",
    "\n",
    "    pad_width = 6\n",
    "    closing_iter1 = 5\n",
    "    closing_iter2 = 1\n",
    "    assert pad_width == closing_iter1 + closing_iter2\n",
    "\n",
    "    vol = np.pad(vol, pad_width=pad_width, mode=\"edge\")\n",
    "    vol = scipy.ndimage.binary_closing(\n",
    "        vol, structure=structure, iterations=closing_iter1, border_value=0\n",
    "    )\n",
    "    vol = scipy.ndimage.binary_opening(\n",
    "        vol, structure=structure, iterations=5, border_value=0\n",
    "    )\n",
    "    vol = scipy.ndimage.binary_closing(\n",
    "        vol, structure=structure, iterations=closing_iter2, border_value=0\n",
    "    )\n",
    "    vol = vol[pad_width:-pad_width, pad_width:-pad_width, pad_width:-pad_width]\n",
    "\n",
    "    assert vol_shape == vol.shape\n",
    "    return vol\n",
    "\n",
    "\n",
    "is_epidermis_s = postprocess_epidermis_seg(is_epidermis)\n",
    "\n",
    "mip_epidermis_overlay_s = calculate_segmentation_overlay(mip_rgb, is_epidermis_s, 1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(mip_epidermis_overlay)\n",
    "ax[1].imshow(mip_epidermis_overlay_s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask the epidermis region from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_and_cut_epidermis(vol_lf_, vol_hf_, segmentation, offset=10):\n",
    "    vol_lf = copy.deepcopy(vol_lf_)\n",
    "    vol_hf = copy.deepcopy(vol_hf_)\n",
    "    assert (\n",
    "        vol_lf.shape == segmentation.shape\n",
    "    ), \"Shapes of raw data and segmentation do not match.\"\n",
    "\n",
    "    # use projection to 1D to estimate start and end of epidermis in z-direction\n",
    "    label_sum = np.sum(segmentation.astype(np.float32), axis=(1, 2))\n",
    "\n",
    "    # normalize\n",
    "    label_sum /= np.amax(label_sum)\n",
    "\n",
    "    # define cutoff parameter for layer intensity\n",
    "    cutoff = 0.05\n",
    "\n",
    "    label_sum_bin = label_sum > cutoff\n",
    "    label_sum_idx = np.squeeze(np.nonzero(label_sum_bin))\n",
    "\n",
    "    # cut at the last index where the sum of segmentation is larger than the cutoff parameter\n",
    "    # and add an offset parameter\n",
    "\n",
    "    offset = 10\n",
    "    layer_end = label_sum_idx[-1] + offset\n",
    "    \n",
    "    print(\"Cutting at\", layer_end)\n",
    "    vol_lf = vol_lf[layer_end:, ...]\n",
    "    vol_hf = vol_hf[layer_end:, ...]\n",
    "    return vol_lf, vol_hf\n",
    "\n",
    "\n",
    "raw_rsom_lf_cropped, raw_rsom_hf_cropped = mask_and_cut_epidermis(\n",
    "    raw_rsom_lf, raw_rsom_hf, is_epidermis_s\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the input data for the vessel segmentation.\n",
    "Create the function to transform the input to a tensor and the inverse function to transform it back to a np.ndarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_vol_rgb = prepare_rgb_volume(\n",
    "    raw_rsom_lf_cropped,\n",
    "    raw_rsom_hf_cropped,\n",
    "    upper_bound={\"lf\": 0.25, \"hf\": 0.15},\n",
    "    lower_bound={\"lf\": 0.05, \"hf\": 0.05},\n",
    ")\n",
    "\n",
    "\n",
    "def get_patch(volume, index, divs=(2, 2, 2), offset=(6, 6, 6)):\n",
    "    \"\"\"\n",
    "    Get subvolume patch from volume\n",
    "    Args:\n",
    "        - volume (np.array)         :   The volume to cut\n",
    "                                        N Dimensions:\n",
    "                                        single channel   : (X_1,..., X_N)\n",
    "                                        multi channel    : (X_1,..., X_N, C)\n",
    "        - index (int)               :   flattened patch iterator.\n",
    "                                        in range 0 to prod(divs)-1\n",
    "        - divs (tuple)              :   Amount to divide each dimension\n",
    "                                        len(divs) must be equal to N\n",
    "        - offset (tuple)            :   Offset for each div\n",
    "                                        len(offset) must be equal to N\n",
    "\n",
    "    Output:\n",
    "        - patch (np.array)          :   patch at index\n",
    "    \"\"\"\n",
    "    if isinstance(divs, int):\n",
    "        divs = (divs,)\n",
    "    if isinstance(offset, int):\n",
    "        offset = (offset,)\n",
    "\n",
    "    assert len(volume.shape) == len(divs) or len(volume.shape) == len(divs) + 1\n",
    "    assert len(volume.shape) == len(offset) or len(volume.shape) == len(offset) + 1\n",
    "\n",
    "    if len(volume.shape) == len(divs) + 1:\n",
    "        # multi channel\n",
    "        shape = volume.shape[:-1]\n",
    "    else:\n",
    "        # single channel\n",
    "        shape = volume.shape\n",
    "\n",
    "    if np.any(np.mod(shape, divs)):\n",
    "        warnings.warn(\n",
    "            (\n",
    "                \"At least one dimension of the input volume can't be \"\n",
    "                \"divided by divs without remainder. Your input shape \"\n",
    "                \"and reconstructed shapes won't match.\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    widths = [int(s / d) for s, d in zip(shape, divs)]\n",
    "    patch_shape = [w + o * 2 for w, o in zip(widths, offset)]\n",
    "\n",
    "    # create nd index\n",
    "    index_ = np.unravel_index(index, divs)\n",
    "\n",
    "    # coordinates\n",
    "    c = [s * d for s, d in zip(index_, widths)]\n",
    "\n",
    "    if len(volume.shape) == len(divs) + 1:\n",
    "        patch_shape = tuple(patch_shape + [volume.shape[-1]])\n",
    "    else:\n",
    "        patch_shape = tuple(patch_shape)\n",
    "\n",
    "    patch = np.zeros(patch_shape, dtype=volume.dtype)\n",
    "\n",
    "    s_ = []\n",
    "    e_ = []\n",
    "    slice_idx = []\n",
    "    slice_idx_patch = []\n",
    "    # for every dimension X_1 ... X_N\n",
    "    for dim in np.arange(len(c)):\n",
    "        # calculate start and end index of the patch\n",
    "        s_ = c[dim] - offset[dim] if c[dim] - offset[dim] >= 0 else 0\n",
    "        e_ = (\n",
    "            c[dim] + widths[dim] + offset[dim]\n",
    "            if c[dim] + widths[dim] + offset[dim] <= shape[dim]\n",
    "            else shape[dim]\n",
    "        )\n",
    "        slice_idx.append(slice(s_, e_))\n",
    "\n",
    "        # start and end index considering offset\n",
    "        ps_ = offset[dim] - (c[dim] - s_)\n",
    "        pe_ = ps_ + (e_ - s_)\n",
    "        slice_idx_patch.append(slice(ps_, pe_))\n",
    "\n",
    "    slice_idx = tuple(slice_idx)\n",
    "    slice_idx_patch = tuple(slice_idx_patch)\n",
    "\n",
    "    # cut out current patch\n",
    "    vp = volume[slice_idx]\n",
    "\n",
    "    # for offset\n",
    "    patch[slice_idx_patch] = vp\n",
    "    return patch\n",
    "\n",
    "\n",
    "def get_volume(patches, divs = (2,2,3), offset=(6,6,6)):\n",
    "    '''\n",
    "    Args:\n",
    "        - patches (np.array)         :  The patches to reconstruct. N_P patches\n",
    "                                        are stacked along first dimension.\n",
    "                                        single channel : (N_P, X_1,..., X_N)\n",
    "                                        multi channel  : (N_P, X_1,..., X_N, C)\n",
    "        - divs (tuple)              :   Amount to divide each dimension\n",
    "                                        len(divs) must be equal to N \n",
    "        - offset (tuple)            :   Offset for each div\n",
    "                                        len(offset) must be equal to N\n",
    "                                      \n",
    "    Output:\n",
    "        - volume  (np.array)        :   patches reconstructed to volume\n",
    "                                        single channel : (X_1,..., X_N)\n",
    "                                        multi channel  : (X_1,..., X_N, C)\n",
    "    '''\n",
    "    if isinstance(divs, int):\n",
    "        divs = (divs,)\n",
    "    if isinstance(offset, int):\n",
    "        offset = (offset,)\n",
    "\n",
    "    new_shape = [(ps -of*2)*int(d) \\\n",
    "                 for ps, of, d in zip(patches.shape[1:], offset, divs)]\n",
    "    \n",
    "    if len(patches.shape) == len(divs) + 2:\n",
    "        # multi channel\n",
    "        new_shape = tuple(new_shape + [patches.shape[-1]])\n",
    "    else:\n",
    "        # single channel\n",
    "        new_shape = tuple(new_shape)\n",
    "    \n",
    "    volume = np.zeros(new_shape, dtype=patches.dtype)\n",
    "    shape = volume.shape\n",
    "    widths = [int(s/d) for s, d in zip(shape, divs)]\n",
    "    # iterate over patch indices\n",
    "    for index in np.arange(np.prod(divs)):\n",
    "        index_ = np.unravel_index(index, divs)\n",
    "        slice_idx = []\n",
    "        slice_idx_offs = []\n",
    "        # iterate over dimension X_1 ... X_N\n",
    "        for dim in np.arange(len(index_)):\n",
    "            # calculate start and end index inside volume\n",
    "            s_ = (index_[dim] * widths[dim])\n",
    "            e_ = ((index_[dim] + 1) * widths[dim])\n",
    "            slice_idx.append(slice(s_, e_))\n",
    "            \n",
    "            # calculate start and end index inside patch,\n",
    "            # to ret rid of the offset\n",
    "            ps_ = offset[dim]\n",
    "            pe_ = offset[dim] + widths[dim]\n",
    "            slice_idx_offs.append(slice(ps_, pe_))\n",
    "            \n",
    "        patch = patches[index,...]\n",
    "        volume[tuple(slice_idx)] = patch[tuple(slice_idx_offs)]\n",
    "    return volume\n",
    "\n",
    "\n",
    "def prepare_tensor_vesselseg_patches(data, divs):\n",
    "    offset = (6, 6, 6)\n",
    "\n",
    "    initial_shape = data.shape\n",
    "    \n",
    "    patches = []\n",
    "    crop = {}\n",
    "    \n",
    "    # crop data in order to be dividable by divs\n",
    "    rem = np.mod(data.shape[: len(divs)], divs)\n",
    "    assert len(rem) == 3, \"Other cases are not implemented. In general our data is 3D.\"\n",
    "\n",
    "    if rem[0]:\n",
    "        data = data[int(np.floor(rem[0] / 2)) : -int(np.ceil(rem[0] / 2)), ...]\n",
    "\n",
    "    if rem[1]:\n",
    "        data = data[:, int(np.floor(rem[1] / 2)) : -int(np.ceil(rem[1] / 2)), ...]\n",
    "\n",
    "    if rem[2]:\n",
    "        data = data[:, :, int(np.floor(rem[2] / 2)) : -int(np.ceil(rem[2] / 2)), ...]\n",
    "\n",
    "    # add to meta information, how much has been cropped\n",
    "    crop[\"begin\"] = torch.from_numpy(\n",
    "        np.array(\n",
    "            [np.floor(rem[0] / 2), np.floor(rem[1] / 2), np.floor(rem[2] / 2), 0],\n",
    "            dtype=int,\n",
    "        )\n",
    "    )\n",
    "    crop[\"end\"] = torch.from_numpy(\n",
    "        np.array(\n",
    "            [np.ceil(rem[0] / 2), np.ceil(rem[1] / 2), np.ceil(rem[2] / 2), 0],\n",
    "            dtype=int,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    assert np.all(\n",
    "        np.array(initial_shape)\n",
    "        == crop[\"begin\"].numpy()\n",
    "        + crop[\"end\"].numpy()\n",
    "        + np.array(data.shape)\n",
    "    ), \"Shapes and Crop do not match\"\n",
    "\n",
    "    for idx in range(np.prod(divs)):\n",
    "        patch_data = get_patch(data, idx, divs, offset)\n",
    "        patch_data_tensor = torch.from_numpy(np.moveaxis(patch_data[..., :2], -1, 0))\n",
    "        patch_data_tensor = torch.unsqueeze(patch_data_tensor, 0)\n",
    "        patches.append(patch_data_tensor)\n",
    "    return patches, crop\n",
    "\n",
    "\n",
    "def prepare_tensor_vesselseg(data_):\n",
    "    data = np.pad(data_, ((6, 6), (6, 6), (6, 6), (0, 0)), \"constant\")\n",
    "    data_tensor = torch.from_numpy(np.moveaxis(data[..., :2], -1, 0))\n",
    "    return torch.unsqueeze(data_tensor, 0)\n",
    "\n",
    "\n",
    "def to_numpy_ves(volume):\n",
    "    if isinstance(volume, torch.Tensor):\n",
    "        volume = volume.numpy()\n",
    "\n",
    "    # removes batch and channel dim\n",
    "    volume = np.squeeze(volume)\n",
    "\n",
    "    return np.ascontiguousarray(volume)\n",
    "\n",
    "\n",
    "# smaller GPUS have to use patches\n",
    "vesselseg_use_patches = True\n",
    "\n",
    "if vesselseg_use_patches:\n",
    "    divs = (1, 1, 2)\n",
    "    data_ves, crop = prepare_tensor_vesselseg_patches(vessel_vol_rgb, divs)\n",
    "else:\n",
    "    data_ves = prepare_tensor_vesselseg(vessel_vol_rgb)\n",
    "    # data_ves.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vessel Segmentation Model\n",
    "\n",
    "Define the DeepVesselNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepVesselNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels=(2, 5, 10, 20, 50, 1),\n",
    "        kernels=(3, 5, 5, 3, 1),\n",
    "        groupnorm=True,\n",
    "        depth=5,\n",
    "    ):\n",
    "        super(DeepVesselNet, self).__init__()\n",
    "\n",
    "        self.depth = depth\n",
    "\n",
    "        # generate channels list for every layer\n",
    "        self.channels = channels\n",
    "\n",
    "        # generate kernel size list\n",
    "        self.kernels = kernels\n",
    "\n",
    "        if groupnorm:\n",
    "            self.groupnorms = [0] + [1] * (depth - 2) + [0]\n",
    "        else:\n",
    "            self.groupnorms = [0] * depth\n",
    "\n",
    "        assert len(self.channels) == depth + 1\n",
    "        assert len(self.kernels) == depth\n",
    "        assert len(self.groupnorms) == depth\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # deep layers\n",
    "        for i in range(depth - 1):\n",
    "            layers.append(\n",
    "                DVN_Block(\n",
    "                    self.channels[i],\n",
    "                    self.channels[i + 1],\n",
    "                    self.kernels[i],\n",
    "                    self.groupnorms[i],\n",
    "                )\n",
    "            )\n",
    "        # last layer\n",
    "        layers.append(nn.Conv3d(self.channels[-2], self.channels[-1], self.kernels[-1]))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "class DVN_Block(nn.Module):\n",
    "    def __init__(self, in_size, out_size, kernel_size, groupnorm):\n",
    "        super(DVN_Block, self).__init__()\n",
    "\n",
    "        block = []\n",
    "\n",
    "        block.append(nn.Conv3d(in_size, out_size, kernel_size))\n",
    "        block.append(nn.ReLU())\n",
    "        if groupnorm:\n",
    "            block.append(nn.GroupNorm(5, out_size))\n",
    "\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "model = DeepVesselNet()\n",
    "model.load_state_dict(torch.load(model_file_vesselseg))\n",
    "\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Override the device if your GPU doesn't have enough memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda_dtype = torch.bfloat16\n",
    "cuda_dtype = torch.float32\n",
    "\n",
    "model.to(device, cuda_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the inference function and run the vessel segmentation prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, model):\n",
    "    pred_tensor = model(data.to(device, cuda_dtype)).detach().to(\"cpu\")\n",
    "    prob_tensor = torch.sigmoid(pred_tensor)\n",
    "    return to_numpy_ves(prob_tensor)\n",
    "\n",
    "def predict_patches(data, model, crop):\n",
    "    patches = []\n",
    "    for patch in data:\n",
    "        pred = model(patch.to(device, cuda_dtype)).detach().to(\"cpu\")\n",
    "        prob = torch.sigmoid(pred)\n",
    "        patches.append(to_numpy_ves(prob))\n",
    "\n",
    "    \n",
    "    prob_volume = get_volume(np.stack(patches, axis=0), divs=divs, offset=(0, 0, 0))\n",
    "\n",
    "    b = crop['begin']\n",
    "    e = crop['end']\n",
    "\n",
    "    pad_width = ((b[0], e[0]), (b[1], e[1]), (b[2], e[2]))\n",
    "    \n",
    "    prob_volume = np.pad(prob_volume, pad_width, 'edge')\n",
    "    \n",
    "    assert prob_volume.shape[1] == 171\n",
    "    assert prob_volume.shape[2] == 333\n",
    "\n",
    "    return prob_volume\n",
    "\n",
    "\n",
    "if vesselseg_use_patches:\n",
    "    prediction = predict_patches(data_ves, model, crop)\n",
    "else:\n",
    "    prediction = predict(data_ves, model)\n",
    "\n",
    "\n",
    "is_vessel = prediction >= 0.95\n",
    "\n",
    "pad_shape = list(is_vessel.shape)\n",
    "pad_shape[0] = raw_rsom_lf.shape[0] - pad_shape[0]\n",
    "\n",
    "is_vessel = np.concatenate([np.zeros(pad_shape, dtype=is_vessel.dtype), is_vessel])\n",
    "\n",
    "assert is_vessel.shape == is_epidermis.shape == raw_rsom_lf.shape == raw_rsom_hf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vessel Segmentation Results\n",
    "\n",
    "Visualize the vessel segmentation results in 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mip_epidermis_vessel_overlay = copy.deepcopy(mip_epidermis_overlay)\n",
    "mip_epidermis_vessel_overlay[..., 2] += 255 * np.max(is_vessel, axis=1).astype(np.uint8)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(mip_rgb)\n",
    "ax[1].imshow(mip_epidermis_vessel_overlay)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The paper restricts the extraction of vascular features to a Region Of Interest (ROI), especially to exclude misclassifications in the upper dermal part. In high-quality samples like this one, we are able to extract vascular features from the entire vessel segmentation mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ves_seg = is_vessel\n",
    "ep_seg = is_epidermis_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify the following configuration parameters in a python dict.\n",
    "\n",
    "| Parameter             | Description|\n",
    "|:---------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| min_size                   | Vessel Segmentation: Objects with a volume smaller than `min_size` pixels are removed from the vessel segmentation to maintain large independent vessels solely.                                                                                |\n",
    "| min_component_length       | Metric Graph: Connected components smaller than `min_component_length` pixels are removed from the metric graph to discard small unpaired artifacts.                                                                                    |\n",
    "| min_end_branch_length      | Metric Graoh: We remove ending branches of the metric graph smaller than `min_end_branch_length` pixel to capture the actual underlying topology better.                                                                             |\n",
    "| delta      | Metric Graph: Delta relates to the construction of the Rips-Vietoris graph. Rips-Vietoris graph is an abstract simplicial complex that can be defined from any metric space and distance `delta` by forming a simplex for every finite set of points that has diameter at most `delta`. (For further details [click here](https://www.jmlr.org/papers/volume15/lecci14a/lecci14a.pdf))  |\n",
    "| r      | Metric Graph: The radius `r` of the shell that is constructed around each point. (For further details [click here](https://www.jmlr.org/papers/volume15/lecci14a/lecci14a.pdf)) |\n",
    "| p11      | Metric Graph: The Euclidean distance `p11` within which all points from a preliminary vertex point are labeled as vertices. (For further details [click here](https://www.jmlr.org/papers/volume15/lecci14a/lecci14a.pdf)) |\n",
    "| save_features_csv_path      | Results: The path where to save the features csv to. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"min_size\": 1000,\n",
    "          \"min_comp_length\": 50,\n",
    "          \"min_end_branch_length\": 20,\n",
    "          \"delta\": 2,\n",
    "          \"r\": 1.5,\n",
    "          \"p11\": 0.9,\n",
    "          \"save_features_csv_path\": \"./features.csv\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a python dictionary to store extracted volumetric and graph features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dict()\n",
    "features[\"volumetric\"] = dict()\n",
    "features[\"graph\"] = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Volumetric Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess segmentation mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ves_seg_clean = skimage.morphology.remove_small_objects(ves_seg.astype(bool), config[\"min_size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract volumetric features directly from the vessel and the epidermis segmentation mask:\n",
    "\n",
    "|Feature|Description|Unit|\n",
    "|-------|-----------|----|\n",
    "|total_blood_volume|Volume of the vessel segmentation mask|µm³|\n",
    "|epidermis_width|Average width in z-direction of the epidermis segmentation mask|µm³|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"volumetric\"][\"total_blood_volume\"] = ves_seg_clean.sum() * 12 * 12 * 3\n",
    "features[\"volumetric\"]['epidermis_width'] = ((ep_seg.sum() / ep_seg.shape[1]) / ep_seg.shape[2]) * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Graph Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, extract the skeleton from the vessel segmentation mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vessel_radii(vol):\n",
    "    \"\"\"\n",
    "    Extract vessel radii from volume.\n",
    "    \"\"\"\n",
    "    vol_clean = scipy.ndimage.binary_closing(vol, iterations=2).astype(np.uint8)\n",
    "    vol_clean = np.asarray(scipy.ndimage.binary_fill_holes(vol_clean), dtype='uint8')\n",
    "    skeleton = skimage.morphology.skeletonize_3d(vol_clean).astype(dtype='uint8')\n",
    "    transf = scipy.ndimage.distance_transform_edt(vol_clean, return_indices=False)\n",
    "    radii = transf * skeleton\n",
    "    return radii\n",
    "\n",
    "vessel_radii = extract_vessel_radii(ves_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we extract the metric graph from the skeleton. Note that this implementation bases on the 2d implementation from:\n",
    "* github: https://github.com/markolalovic/metric-graph-reconstruction\n",
    "* author: @markolalovic\n",
    "\n",
    "Note: This is an expensive operation and may take up to 4h per sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing(func):\n",
    "    \"\"\"\n",
    "    timing decorator\n",
    "    Args:\n",
    "        func: function handle\n",
    "\n",
    "    Returns: timing function wrapper\n",
    "\n",
    "    \"\"\"\n",
    "    def wrapper(*arg, **kw):\n",
    "        t1 = time.time()\n",
    "        res = func(*arg, **kw)\n",
    "        t2 = time.time()\n",
    "        print(func.__name__, 'took', t2 - t1, 's')\n",
    "        return res\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "class EmbeddedGraph:\n",
    "    def __init__(self, nodes, edges, radius=[]):\n",
    "        \"\"\"\n",
    "        Graph with points embedded in the plane.\n",
    "        \"\"\"\n",
    "        self.nodes = PointList(nodes)\n",
    "        self.edges = [PointList(edge) for edge in edges]\n",
    "        self.radius = radius\n",
    "\n",
    "    def __str__(self):\n",
    "        points = [str(point) for point in self.nodes.points]\n",
    "        edges = [str(edge) for edge in self.edges]\n",
    "        components = [str(cmpt_emb_G) for cmpt_emb_G in self.components.values()]\n",
    "\n",
    "        return \"nodes: {}\\edges: {}\\ncomponents: {}\".format(\n",
    "            str(points), str(edges), str(components))\n",
    "\n",
    "    def to_dict(self):\n",
    "        \"\"\" Converts EmbeddedGraph to dict.\"\"\"\n",
    "        points = [point.to_tuple() for point in self.nodes.points]\n",
    "        edges = [edge.to_list() + [r] for edge, r in zip(self.edges, self.radius)]\n",
    "        components = [cmpt_emb_G.to_list() for cmpt_emb_G in self.components.values()]\n",
    "\n",
    "        embedded_graph = dict()\n",
    "        embedded_graph[\"points\"] = points\n",
    "        embedded_graph[\"edges\"] = edges\n",
    "        embedded_graph[\"components\"] = components\n",
    "\n",
    "        return embedded_graph\n",
    "\n",
    "    @property\n",
    "    def n(self):\n",
    "        \"\"\" Number of nodes in EmbeddedGraph.\"\"\"\n",
    "        return len(self.nodes.points)\n",
    "\n",
    "    @property\n",
    "    def m(self):\n",
    "        \"\"\" Number of edges in EmbeddedGraph.\"\"\"\n",
    "        return len(self.edges)\n",
    "\n",
    "    @property\n",
    "    def k(self):\n",
    "        \"\"\" Number of connected components of EmbeddedGraph.\"\"\"\n",
    "        return len(self.components)\n",
    "\n",
    "    @property\n",
    "    def components(self):\n",
    "        \"\"\" Computes connected components of EmbeddedGraph\"\"\"\n",
    "        graph_G = graph(self)\n",
    "        cmpts_G = graph_G.components\n",
    "\n",
    "        cmpts_emb_G = {}\n",
    "        point_of = {}\n",
    "        for i in range(self.n):\n",
    "            point_of[i] = self.nodes.points[i]\n",
    "\n",
    "        for i, cmpt_G in cmpts_G.items():\n",
    "            cmpts_emb_G[i] = PointList([point_of[j] for j in cmpt_G])\n",
    "\n",
    "        return cmpts_emb_G\n",
    "\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, nodes, edges):\n",
    "        \"\"\" Graph represented with nodes and edges.\"\"\"\n",
    "        if isinstance(nodes, list):\n",
    "            self.nodes = nodes\n",
    "        else:\n",
    "            self.nodes = list(nodes)\n",
    "        if isinstance(edges, list):\n",
    "            self.edges = edges\n",
    "        else:\n",
    "            self.edges = list(edges)\n",
    "\n",
    "    @property\n",
    "    def n(self):\n",
    "        \"\"\" Number of nodes in Graph.\"\"\"\n",
    "        return len(self.nodes)\n",
    "\n",
    "    @property\n",
    "    def m(self):\n",
    "        \"\"\" Number of edges in Graph.\"\"\"\n",
    "        return len(self.edges)\n",
    "\n",
    "    @property\n",
    "    def k(self):\n",
    "        \"\"\" Number of connected components of Graph.\"\"\"\n",
    "        return len(self.components)\n",
    "\n",
    "    @property\n",
    "    def components(self):\n",
    "        \"\"\" Computes connected components of Graph\"\"\"\n",
    "        cmpts = {}\n",
    "        k = 0\n",
    "        unvisited = copy.copy(self.nodes)\n",
    "        for v in self.nodes:\n",
    "            if v in unvisited:\n",
    "                comp_of_v = component(v, self.nodes, self.edges)\n",
    "                # remove visited nodes in component from unvisited\n",
    "                unvisited = list(set(unvisited) - set(comp_of_v))\n",
    "                cmpts[k] = comp_of_v\n",
    "                k += 1\n",
    "\n",
    "        return cmpts\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"nodes: {}\\nedges: {}\".format(str(self.nodes), str(self.edges))\n",
    "\n",
    "\n",
    "def nhbs(v, graph_G):\n",
    "    N = []\n",
    "    for edge in graph_G.edges:\n",
    "        u1, u2 = edge\n",
    "        if u1 == v:\n",
    "            N.append(u2)\n",
    "        elif u2 == v:\n",
    "            N.append(u1)\n",
    "    return N\n",
    "\n",
    "\n",
    "def component(v, nodes, edges):\n",
    "    \"\"\" Wrapper of comp.\"\"\"\n",
    "    G = Graph(nodes, edges)\n",
    "    return comp(v, G, [v])  # T=[v] at the start\n",
    "\n",
    "\n",
    "def comp(v, graph_G, T):\n",
    "    N = list(set(nhbs(v, graph_G)) - set(T))\n",
    "    if N == []:\n",
    "        return [v]\n",
    "    else:\n",
    "        T += N  # expand the tree\n",
    "        for n in N:\n",
    "            T += comp(n, graph_G, T)  # expand the tree (BFS)\n",
    "    return list(set(T))\n",
    "\n",
    "\n",
    "def graph(emb_G):\n",
    "    \"\"\" Translate from EmbeddedGraph to Graph.\"\"\"\n",
    "\n",
    "    point_of = {}\n",
    "    for i in range(emb_G.n):\n",
    "        point_of[i] = emb_G.nodes.points[i]\n",
    "\n",
    "    number_of = {}\n",
    "    for i in range(emb_G.n):\n",
    "        number_of[emb_G.nodes.points[i]] = i\n",
    "\n",
    "    nodes = list(point_of.keys())\n",
    "    edges = []\n",
    "    for i in range(emb_G.n):\n",
    "        for j in range(i + 1, emb_G.n):\n",
    "            # test if there is an edge between Points v1 and v2\n",
    "            v1 = emb_G.nodes.points[i]\n",
    "            v2 = emb_G.nodes.points[j]\n",
    "\n",
    "            for edge in emb_G.edges:\n",
    "                u1 = edge.points[0]\n",
    "                u2 = edge.points[1]\n",
    "                if v1.equal(u1) and v2.equal(u2) or \\\n",
    "                        v1.equal(u2) and v2.equal(u1):\n",
    "                    edges.append((number_of[v1], number_of[v2]))\n",
    "\n",
    "    return Graph(nodes, edges)\n",
    "\n",
    "\n",
    "class Point:\n",
    "    \"\"\" Class Point for storing coordinates and label of a point.\n",
    "\n",
    "    Args:\n",
    "        x::float\n",
    "            The x coordinate of the point.\n",
    "        y::float\n",
    "            The y coordinate of the point.\n",
    "        label::str\n",
    "            Should be: 'E' for edge point and 'V' for vertex point.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x=0, y=0, z=0, radius=0, label=''):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "        self.radius = radius\n",
    "        if label not in ('E', 'V', ''):\n",
    "            raise ValueError(\"Label must be 'E' or 'V'\")\n",
    "        self.label = label\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"({}, {}, {})\".format(self.x, self.y, self.z, self.label)\n",
    "\n",
    "    def to_tuple(self):\n",
    "        \"\"\"Converts Point to tuple.\"\"\"\n",
    "        return self.x, self.y, self.z\n",
    "\n",
    "    def equal(self, p):\n",
    "        return (self.x == p.x) and (self.y == p.y) and (self.z == p.z)\n",
    "\n",
    "\n",
    "class PointList:\n",
    "    def __init__(self, points):\n",
    "        \"\"\" PointList Class to hold a list of Point objects.\"\"\"\n",
    "        if points == [] or isinstance(points[0], Point):\n",
    "            self.points = points\n",
    "        else:\n",
    "            raise ValueError(\"Args must be a list of Points.\")\n",
    "\n",
    "    @property\n",
    "    def vertex_points(self):\n",
    "        vertex_points = []\n",
    "        for point in self.points:\n",
    "            if point.label == 'V':\n",
    "                vertex_points.append(point)\n",
    "\n",
    "        return vertex_points\n",
    "\n",
    "    @property\n",
    "    def edge_points(self):\n",
    "        edge_points = []\n",
    "        for point in self.points:\n",
    "            if point.label == 'E':\n",
    "                edge_points.append(point)\n",
    "\n",
    "        return edge_points\n",
    "\n",
    "    @property\n",
    "    def center(self):\n",
    "        \"\"\" Center of mass of the point cloud.\"\"\"\n",
    "        x = np.mean(np.array([point.x for point in self.points]))\n",
    "        y = np.mean(np.array([point.y for point in self.points]))\n",
    "        z = np.mean(np.array([point.z for point in self.points]))\n",
    "        radius = np.mean(np.array([point.radius for point in self.points]))\n",
    "\n",
    "        return Point(x, y, z, radius)\n",
    "\n",
    "    def __str__(self):\n",
    "        return '[' + ','.join(['{!s}'.format(p) for p in self.points]) + ']'\n",
    "\n",
    "    def to_list(self):\n",
    "        \"\"\"Converts PointList to list.\"\"\"\n",
    "        return [p.to_tuple() for p in self.points]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.points)\n",
    "\n",
    "    def contains(self, p):\n",
    "        for pt in self.points:\n",
    "            if pt.x == p.x and pt.y == p.y and pt.z == p.z:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def append(self, p):\n",
    "        self.points.append(p)\n",
    "\n",
    "    def difference(self, pl):\n",
    "        difference = PointList([])\n",
    "        for pt in self.points:\n",
    "            if not pl.contains(pt):\n",
    "                difference.append(pt)\n",
    "        return difference\n",
    "\n",
    "    def distance(self, point_list):\n",
    "        ''' Computes minimum distance from self to another point list.'''\n",
    "        distances = []\n",
    "        for p1 in self.points:\n",
    "            for p2 in point_list.points:\n",
    "                distances.append(distance(p1, p2))\n",
    "\n",
    "        return np.min(np.array(distances))\n",
    "\n",
    "    def avg_radius(self):\n",
    "        radius = []\n",
    "        for p in self.points:\n",
    "            radius.append(p.radius)\n",
    "        return np.array(radius).mean()\n",
    "\n",
    "\n",
    "def distance(p1, p2):\n",
    "    \"\"\" Euclidean distance between p1, p2.\"\"\"\n",
    "    d = (\n",
    "            ((p1.x - p2.x) ** 2) +\n",
    "            ((p1.y - p2.y) ** 2) +\n",
    "            ((p1.z - p2.z) ** 2)\n",
    "        ) ** 0.5\n",
    "    return d\n",
    "\n",
    "\n",
    "def get_shell_points(points, center, r, delta):\n",
    "    \"\"\" Returns a list of points between r and r + delta around the center\n",
    "    point.\"\"\"\n",
    "    shell_points = []\n",
    "    for point in points:\n",
    "        d = distance(center, point)\n",
    "        if d >= r and d <= r + delta:\n",
    "            shell_points.append(point)\n",
    "\n",
    "    return shell_points\n",
    "\n",
    "\n",
    "def get_ball_points(points, center, r):\n",
    "    ball_points = []\n",
    "    for point in points:\n",
    "        d = distance(center, point)\n",
    "        if d < r:\n",
    "            ball_points.append(point)\n",
    "\n",
    "    return ball_points\n",
    "\n",
    "\n",
    "def rips_vietoris_graph(delta, points):\n",
    "    \"\"\" Constructs the Rips-Vietoris graph of parameter delta whose nodes\n",
    "    are points of the shell.\"\"\"\n",
    "    n = len(points)\n",
    "    nodes = []\n",
    "    edges = []\n",
    "    for i in range(n):\n",
    "        p1 = points[i]\n",
    "        nodes.append(p1)\n",
    "        for j in range(i, n):\n",
    "            p2 = points[j]\n",
    "            if not p1.equal(p2) and distance(p1, p2) < delta:\n",
    "                edges.append([p1, p2])\n",
    "\n",
    "    return EmbeddedGraph(nodes, edges)\n",
    "\n",
    "def volume_to_point_list(vol):\n",
    "    \"\"\"\n",
    "    Construct PointList instance from volume.\n",
    "    \"\"\"\n",
    "    # flip z-axis for coordinate system conversion\n",
    "    vol = np.flip(vol, 0)\n",
    "    # get shapes, note that we need to configure x-y-z ordering\n",
    "    x = vol.shape[2]\n",
    "    y = vol.shape[1]\n",
    "    z = vol.shape[0]\n",
    "    # list of points\n",
    "    points = []\n",
    "    for x_idx in range(x):\n",
    "        for y_idx in range(y):\n",
    "            for z_idx in range(z):\n",
    "                radius = vol[z_idx, y_idx, x_idx]\n",
    "                if radius > 0.:\n",
    "                    points.append(Point(x_idx, y_idx, z_idx, round(radius, 3)))\n",
    "    return PointList(points)\n",
    "\n",
    "@timing\n",
    "def reconstruct_graph(point_list, delta, r, p11):\n",
    "    \"\"\"\n",
    "    Implementation of Aanjaneya's metric graph reconstruction algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    # label the points as edge or vertex points\n",
    "    for center in point_list.points:\n",
    "        shell_points = get_shell_points(point_list.points, center, r, delta)\n",
    "        rips_embedded = rips_vietoris_graph(delta, shell_points)\n",
    "\n",
    "        if rips_embedded.k == 2:\n",
    "            center.label = 'E'\n",
    "        else:\n",
    "            center.label = 'V'\n",
    "\n",
    "    # re-label all the points withing distance p11 from vertex points as vertices\n",
    "    for center in point_list.vertex_points:\n",
    "        ball_points = get_ball_points(point_list.edge_points, center, p11)\n",
    "        for ball_point in ball_points:\n",
    "            ball_point.label = 'V'\n",
    "\n",
    "    # reconstruct the graph structure\n",
    "    # compute the connected components of Rips-Vietoris graphs:\n",
    "    # R_delta(vertex_points), R_delta(edge_points)\n",
    "    rips_V = rips_vietoris_graph(delta, point_list.vertex_points)\n",
    "    rips_E = rips_vietoris_graph(delta, point_list.edge_points)\n",
    "    cmpts_V = rips_V.components\n",
    "\n",
    "    # takes a long time\n",
    "    cmpts_E = rips_E.components\n",
    "\n",
    "    nodes_emb_G = []\n",
    "    for i, cmpt_V in cmpts_V.items():\n",
    "        nodes_emb_G.append(cmpt_V.center)\n",
    "    n = len(nodes_emb_G)\n",
    "    edges_emb_G = []\n",
    "    radius = []\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            for cmpt_E in cmpts_E.values():\n",
    "                if cmpts_V[i].distance(cmpt_E) < delta and \\\n",
    "                        cmpts_V[j].distance(cmpt_E) < delta:\n",
    "                    edges_emb_G.append([nodes_emb_G[i], nodes_emb_G[j]])\n",
    "                    radius.append(cmpt_E.avg_radius())\n",
    "\n",
    "    emb_G = EmbeddedGraph(nodes_emb_G, edges_emb_G, radius)\n",
    "    return emb_G\n",
    "\n",
    "point_list = volume_to_point_list(vessel_radii)\n",
    "metric_graph = reconstruct_graph(point_list, config[\"delta\"], config[\"r\"], config[\"p11\"]) # 10840s on M1 Pro\n",
    "metric_graph_dict = metric_graph.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now cast the metric graph class structure to a [networkx](https://networkx.org/) graph instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.Graph()\n",
    "nodes = [tuple(n) for n in metric_graph_dict[\"points\"]]\n",
    "edges = [[tuple(e) for e in edge[:2]] + [edge[2]] for edge in metric_graph_dict[\"edges\"]]\n",
    "graph.add_weighted_edges_from(edges, weight='radius')\n",
    "graph.add_nodes_from(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then preprocess the metric graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(p1, p2, mc=True):\n",
    "    \"\"\"\n",
    "    Euclidean distance between tuples p1 and p2.\n",
    "\n",
    "    Args:\n",
    "        p1: point 1 represented as tuple: (x, y, z)\n",
    "        p2: point 2 represented as tuple: (x, y, z)\n",
    "        mc: whether to compute distance in micrometer (given a RSOM pixel space).\n",
    "    \"\"\"\n",
    "    # step size of RSOM laser in x, y, and z direction\n",
    "    step_size_mc = (12, 12, 3)\n",
    "    if not mc:\n",
    "        step_size_mc = (1, 1, 1)\n",
    "    # euclidean distance computation\n",
    "    d = (\n",
    "                (((p1[0]-p2[0]) * step_size_mc[0]) ** 2) +\n",
    "                (((p1[1]-p2[1]) * step_size_mc[1]) ** 2) +\n",
    "                (((p1[2]-p2[2]) * step_size_mc[2]) ** 2)\n",
    "        ) ** 0.5\n",
    "    return d\n",
    "# remove components smaller than min_comp_length\n",
    "graph_clean = nx.Graph()\n",
    "for c in nx.connected_components(graph):\n",
    "    distance = 0\n",
    "    g = graph.subgraph(c)\n",
    "    for edge in g.edges:\n",
    "        distance += compute_distance(edge[0], edge[1], mc=False)\n",
    "    if distance > config[\"min_comp_length\"]:\n",
    "        graph_clean = nx.compose(graph_clean, g)\n",
    "# remove end-branches smaller than min_end_branch_length\n",
    "edges_to_remove = []\n",
    "for e in graph_clean.edges():\n",
    "    if compute_distance(e[0], e[1], mc=False) < config[\"min_end_branch_length\"]:\n",
    "        if graph_clean.degree(e[0]) == 1 or graph_clean.degree(e[1]) == 1:\n",
    "            edges_to_remove.append(e)\n",
    "graph_clean.remove_edges_from(edges_to_remove)\n",
    "# remove isolated nodes eventually caused by previous edge removal\n",
    "graph_clean.remove_nodes_from(list(nx.isolates(graph_clean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the preprocessed metric graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_metric_graph(metric_graph, axis=\"x\"):\n",
    "    \"\"\"\n",
    "    Visualizes metric graph as MIP.\n",
    "\n",
    "    Args:\n",
    "        graph (networkx.graph): the graph as networkx graph instance\n",
    "        axis (str): the axis we project: x, y or z (defaults to \"x\")\n",
    "    \"\"\"\n",
    "    plt.style.use('dark_background')\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    radii = np.array([e[2][\"radius\"] for e in graph_clean.edges(data=True)])\n",
    "    sm = ScalarMappable(cmap='jet', norm=plt.Normalize(0, 5))\n",
    "    sm.set_array(radii)\n",
    "    \n",
    "    for e in metric_graph.edges(data=True):\n",
    "        radius = e[2][\"radius\"]\n",
    "        if axis == \"x\":\n",
    "            edge = ax.plot([y for x, y, z in e[:2]], [z for x, y, z in e[:2]], linewidth=5, alpha=0.9)\n",
    "        elif axis == \"y\":\n",
    "            edge = ax.plot([x for x, y, z in e[:2]], [z for x, y, z in e[:2]], linewidth=5, alpha=0.9)\n",
    "        elif axis == \"z\":\n",
    "            edge = ax.plot([x for x, y, z in e[:2]], [y for x, y, z in e[:2]], linewidth=5, alpha=0.9)\n",
    "        else:\n",
    "            raise ValueError(\"Wrong axis specified.\")\n",
    "        edge[0].set_color(sm.to_rgba(radius))\n",
    "        \n",
    "    if axis == \"x\":\n",
    "        ax.scatter([y for x, y, z in metric_graph.nodes], [z for x, y, z in graph_clean.nodes], c=\"white\", s=40, zorder=2.5)\n",
    "        xmax=171\n",
    "        ymax=500\n",
    "    elif axis == \"y\":\n",
    "        ax.scatter([x for x, y, z in metric_graph.nodes], [z for x, y, z in graph_clean.nodes], c=\"white\", s=40, zorder=2.5)\n",
    "        xmax=333\n",
    "        ymax=500\n",
    "    elif axis == \"z\":\n",
    "        ax.scatter([x for x, y, z in metric_graph.nodes], [y for x, y, z in graph_clean.nodes], c=\"white\", s=40, zorder=2.5)\n",
    "        xmax=333\n",
    "        ymax=171\n",
    "    else:\n",
    "        raise ValueError(\"Wrong axis specified.\")\n",
    "        \n",
    "    ax.get_xaxis().set_ticks([])\n",
    "    ax.get_yaxis().set_ticks([])\n",
    "    ax.set_ylim(ymin=0, ymax=ymax)\n",
    "    ax.set_xlim(xmin=0, xmax=xmax)\n",
    "    ax.set_title(f\"MIP in {axis} direction\")\n",
    "    cbar = plt.colorbar(sm, ax=ax, ticks=[0, 5], label='Radius (in px)')\n",
    "    ax.set_box_aspect(ymax/xmax)\n",
    "        \n",
    "visualize_metric_graph(graph_clean, axis=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we extract vascular features from the prepocessed metric graph (`G`). Main features are:\n",
    "\n",
    "\n",
    "|Feature|Description|Unit|\n",
    "|:-------|:-----------|:----|\n",
    "|total_vessel_length|Sum of the length of edges of `G`|mm|\n",
    "|small_vessel_length|Sum of the length of edges of `G` having an average radius smaller than 2.5 pixels|mm|\n",
    "|large_vessel_length|Sum of the length of edges of `G` having an average radius greater than or equal to 2.5 pixels|mm|\n",
    "|#vessel_bifurcations|Number of nodes of `G` with a degree higher than 2|-|\n",
    "\n",
    "\n",
    "Experimental features include: \n",
    "\n",
    "|Feature|Description|Unit|\n",
    "|:--------|:----------|:----|\n",
    "| num_components| Number of connected components of `G`|-|\n",
    "| length_per_component| Average length of the edges per connected component of `G`|mm|\n",
    "| density| [Density](https://networkx.org/documentation/stable/reference/generated/networkx.classes.function.density.html) of `G`|-|\n",
    "| degree_assortativity_coefficient | Measures the similarity of connections in the graph with respect to the node degree ([source](https://networkx.org/documentation/networkx-1.10/reference/generated/networkx.algorithms.assortativity.degree_assortativity_coefficient.html#networkx.algorithms.assortativity.degree_assortativity_coefficient))|-|\n",
    "| num_cycles| Number of cycles of `G`|-|\n",
    "| avg_radius| Average radius of `G`'s edges|pixel|\n",
    "| avg_path_length|Average shortest path length from eacz node to every other node of `G`|mm|                                                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average path length in mm\n",
    "path_lengths = []\n",
    "for v in graph_clean.nodes():\n",
    "    spl = dict(nx.single_source_shortest_path_length(graph_clean, v))\n",
    "    for p in spl:\n",
    "        path_lengths.append(spl[p])\n",
    "features['graph']['avg_path_length'] = np.mean(path_lengths) / 1000\n",
    "\n",
    "# density\n",
    "features['graph']['density'] = nx.density(graph_clean)\n",
    "\n",
    "# degree assortativity coefficient\n",
    "degree_assortativity_coefficient = nx.degree_assortativity_coefficient(graph_clean)\n",
    "if degree_assortativity_coefficient is None:\n",
    "    degree_assortativity_coefficient = 0\n",
    "features['graph']['degree_assortativity_coefficient'] = degree_assortativity_coefficient\n",
    "\n",
    "# number of cycles\n",
    "features['graph']['num_cycles'] = len(nx.cycle_basis(graph_clean))\n",
    "\n",
    "# number of bifurcation points\n",
    "features['graph']['num_vessel_bifurcations'] = len([val for (node, val) in graph_clean.degree() if val > 2])\n",
    "\n",
    "# number of components\n",
    "features['graph']['num_components'] = nx.number_connected_components(graph_clean)\n",
    "\n",
    "# average length per component in mm\n",
    "len_components = []\n",
    "for c in nx.connected_components(graph_clean):\n",
    "    distance = 0\n",
    "    g = graph_clean.subgraph(c)\n",
    "    for edge in g.edges:\n",
    "        distance += compute_distance(edge[0], edge[1])\n",
    "    len_components.append(distance)\n",
    "len_components = np.array(len_components)\n",
    "features['graph']['length_per_component'] = len_components.mean() / 1000\n",
    "\n",
    "# total length of metric graph in mm\n",
    "features['graph']['total_vessel_length'] = len_components.sum() / 1000\n",
    "\n",
    "# average radius in px\n",
    "features['graph']['avg_radius'] = np.array([e[2][\"radius\"] for e in graph_clean.edges(data=True)]).mean()\n",
    "\n",
    "# length of small and large vessels in mm\n",
    "small_vessel_length = 0\n",
    "large_vessel_length = 0\n",
    "for e in graph_clean.edges(data=True):\n",
    "    if e[2][\"radius\"] <= 2.5:\n",
    "        small_vessel_length += compute_distance(e[0], e[1])\n",
    "    else:\n",
    "        large_vessel_length += compute_distance(e[0], e[1])\n",
    "small_vessel_length /= 1000\n",
    "large_vessel_length /= 1000\n",
    "features['graph']['small_vessel_length'] = small_vessel_length\n",
    "features['graph']['large_vessel_length'] = large_vessel_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the features and dump them to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"graph\"] = {k: str(v) for k, v in features[\"graph\"].items()}\n",
    "features[\"volumetric\"] = {k: str(v) for k, v in features[\"volumetric\"].items()}\n",
    "features_str = json.dumps(features, indent=2)\n",
    "print(features_str)\n",
    "with open(config[\"save_features_csv_path\"], 'w') as fd:\n",
    "    fd.write(features_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
